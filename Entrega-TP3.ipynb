{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelomkk/tweetsAnalytics/blob/main/Entrega-TP3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pljdz--nPEEX"
      },
      "source": [
        "**TP3 — Tweets Analytics\n",
        "**Diplomatura en IA — Módulo 3**  \n",
        "Autor: Marcelo Manukian\n",
        "\n",
        "Objetivo: **Vamos a analizar el sentimiento de los tweets\n",
        "\n",
        "Entregables:  \n",
        "\n",
        "Notebook (esta notebook).  \n",
        "\n",
        "Inputs:\n",
        "\n",
        "`training.1600000.processed.noemoticon.csv` 1.6M tweets etiquetados automáticamente.\n",
        "`testdata.manual.2009.06.14.csv` tweets etiquetados manualmente, usados para evaluación final.\n",
        "\n",
        "\n",
        "**En esta versión, los archivos se leen desde Google Drive ya que desde github no puedo subir un archivo tan grande por limitaciones propias de git.**\n",
        "\n",
        "https://docs.google.com/file/d/0B04GJPshIjmPRnZManQwWEdTZjg/edit?resourcekey=0-betyQkEmWZgp8z0DFxWsHw\n",
        "\n",
        "La polaridad:\n",
        "\n",
        "0 Negativo\n",
        "2 Neutral\n",
        "4 Positivo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Realizo Importaciones"
      ],
      "metadata": {
        "id": "UUUjOO98PAD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Zw-5erHdPqt"
      },
      "outputs": [],
      "source": [
        "#Importamos librerias de interes (no hace falta utilizar todas)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Leo los archivos que voy a precisar desde gDrive y cargo Dataframes\n"
      ],
      "metadata": {
        "id": "E1IKxinyPdFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importo los archivos desde gDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path_train = \"//content/drive/MyDrive/Estudio/UP/Especializacion en IA/TP/Entrega3/training.1600000.processed.noemoticon.csv\"\n",
        "path_test = \"/content/drive/MyDrive/Estudio/UP/Especializacion en IA/TP/Entrega/testdata.manual.2009.06.14.csv\"\n",
        "\n",
        "\n",
        "df_train = pd.read_csv(\n",
        "    path_train,\n",
        "    encoding='latin-1',\n",
        "    header=None,\n",
        "    names=cols\n",
        ")\n",
        "\n",
        "df_test = pd.read_csv(\n",
        "    path_test,\n",
        "    encoding='latin-1',\n",
        "    header=None,\n",
        "    names=cols\n",
        ")\n",
        "\n",
        "#Visualizo cuantas columnnas tiene cada dataset, el de entrenamiento y el test\n",
        "df_train.shape, df_test.shape\n",
        "\n",
        "# Visualizo las primeras 5 columnas\n",
        "df_train.head()\n",
        "\n",
        "#Distribucion de polaridades\n",
        "\n",
        "sns.countplot(x=df_train['polarity'])\n",
        "plt.title(\"Distribución de polaridad – Dataset de entrenamiento\")\n",
        "plt.xlabel(\"Polarity (0 = negativo, 2 = neutral, 4 = positivo)\")\n",
        "plt.ylabel(\"Cantidad de tweets\")\n",
        "plt.show()\n",
        "\n",
        "#Ejemplo de tweets crudos\n",
        "df_train[['polarity', 'text']].head(10)"
      ],
      "metadata": {
        "id": "KujFth6aPcVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Conclusiones y Observaciones:\n",
        "\n",
        "Se montaron los dataset desde googleDrive, uno de 1.6 millones de tweets etiquetados automaticamente y un dataset manual para evaluacion final.\n",
        "Se verifica qeu ambos archivos se lean correctamente y se realiza una primera exploracion de estructura, distgribucion de polaridades y ejemplos de tweets brutos para detectar ruido tipico de twitter como ser url, menciones, emoji, hastags, lo que justifica la necesidad de limpiar un poco estos datos."
      ],
      "metadata": {
        "id": "sPzFVwnURlDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CONSIGNAS:\n",
        "\n",
        "El analisis es libre, no tiene limites y se pueden agregar todas las ideas que les surjan, pueden incluir analogias, analisis de sensibilidad, keywords, modelos pre-entrenados, etc... Deben usar al menos una de las distintas metricas que vimos tales como similitud coseno, PMI, etc.\n",
        "\n",
        "Como sugerencia, ambos archivos estan orientados a un analisis de sentimiento por lo que si optan por este caso, pueden usar ambos para ver que tan bien predice su modelo. Les paso la descripcion de cada atributo:\n",
        "\n",
        "0 - the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
        "1 - the id of the tweet (2087)\n",
        "2 - the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
        "3 - the query (lyx). If there is no query, then this value is NO_QUERY.\n",
        "4 - the user that tweeted (robotickilldozr)\n",
        "5 - the text of the tweet (Lyx is cool)\n",
        "\n",
        "(Opcional): Se pueden utilizar graficos (umap, wordclouds) y cualquiera de los algoritmos vistos."
      ],
      "metadata": {
        "id": "sR-ejB890CUo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqIrKZKUPb9u"
      },
      "source": [
        "### Entrega\n",
        "\n",
        "**Fecha limite**: por definir\n",
        "\n",
        "\n",
        "La presentación puede ser desde la misma notebook, pero se pueden utilizar distintas herramientas de visualizacion. La idea es que la presentacion incluya los resultados obtenidos, que decisiones se tomaron y conclusiones. No es necesario explicar el codigo, con mostrar los outputs de cada bloque es suficiente.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 05:59:45) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "892d461b55a6ce994a56bafd67ae2f3489d9f23234c096cfb51dfe498c166e4b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}